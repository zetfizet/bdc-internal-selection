{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LjJlKvzGjReN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from scipy.sparse import hstack\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ri4hoWBlJjJ",
        "outputId": "55519129-197a-46aa-cda9-f9b2f79183ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(r\"/content/df_train.csv\")\n",
        "df_test = pd.read_csv(r\"/content/df_test.csv\")"
      ],
      "metadata": {
        "id": "NE5eRiPxlNGA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()\n",
        "df_test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK-5pS3ylZjF",
        "outputId": "47adbcd7-8012-4ed5-be00-746da7c52176"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9912 entries, 0 to 9911\n",
            "Data columns (total 6 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   prompt                  9912 non-null   object \n",
            " 1   essay                   9912 non-null   object \n",
            " 2   task_achievement        9667 non-null   float64\n",
            " 3   coherence_and_cohesion  9614 non-null   float64\n",
            " 4   lexical_resource        9238 non-null   float64\n",
            " 5   grammatical_range       9041 non-null   float64\n",
            "dtypes: float64(4), object(2)\n",
            "memory usage: 464.8+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 473 entries, 0 to 472\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   prompt  473 non-null    object\n",
            " 1   essay   473 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 7.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "corr_matrix = df_train[score_cols].corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Heatmap Korelasi Antar Skor\", fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vifdAyEtyRvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Panjang esai\n",
        "df_train[\"essay_length\"] = df_train[\"essay\"].apply(lambda x: len(x.split()))\n",
        "df_test[\"essay_length\"] = df_test[\"essay\"].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "-FEZrhgplj_1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buang outlier\n",
        "df_train_clean = df_train[(df_train[\"essay_length\"] >= 50) & (df_train[\"essay_length\"] <= 700)].copy()"
      ],
      "metadata": {
        "id": "hMKx9sw4lrIg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_cols = [\"task_achievement\", \"coherence_and_cohesion\", \"lexical_resource\", \"grammatical_range\"]\n",
        "\n",
        "for col in score_cols:\n",
        "    df_train_clean[col] = df_train_clean[col].replace(0, np.nan)\n",
        "    df_train_clean[col] = df_train_clean[col].fillna(df_train_clean[col].median())\n",
        "\n",
        "# Gabungkan prompt + essay\n",
        "df_train_clean[\"full_text\"] = df_train_clean[\"prompt\"] + \" \" + df_train_clean[\"essay\"]\n",
        "df_test[\"full_text\"] = df_test[\"prompt\"] + \" \" + df_test[\"essay\"]"
      ],
      "metadata": {
        "id": "WRWJ9OheltQp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering"
      ],
      "metadata": {
        "id": "gClqKl8kmQQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def extract_features(text):\n",
        "    words = text.split()\n",
        "    num_words = len(words)\n",
        "    num_sentences = max(1, len(nltk.sent_tokenize(text)))\n",
        "    unique_words = len(set(words))\n",
        "    stopword_count = sum(1 for w in words if w.lower() in stop_words)\n",
        "    punctuation_count = sum(1 for c in text if c in string.punctuation)\n",
        "    return [\n",
        "        len(text),  # char length\n",
        "        num_words,  # word length\n",
        "        np.mean([len(w) for w in words]) if words else 0,  # avg word length\n",
        "        num_sentences,  # number of sentences\n",
        "        num_words / num_sentences,  # avg sentence length\n",
        "        unique_words,  # unique word count\n",
        "        unique_words / num_words if num_words > 0 else 0,  # type-token ratio\n",
        "        stopword_count / num_words if num_words > 0 else 0,  # stopword ratio\n",
        "        punctuation_count  # punctuation count\n",
        "    ]\n",
        "\n",
        "feature_names = [\n",
        "    \"char_length\", \"word_length\", \"avg_word_len\",\n",
        "    \"n_sentences\", \"avg_sentence_len\", \"unique_words\",\n",
        "    \"ttr\", \"stopword_ratio\", \"punctuation_count\"\n",
        "]\n",
        "\n",
        "train_extra_features = np.array([extract_features(t) for t in df_train_clean[\"essay\"]])\n",
        "test_extra_features = np.array([extract_features(t) for t in df_test[\"essay\"]])"
      ],
      "metadata": {
        "id": "vLQoHlpzmR65"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF"
      ],
      "metadata": {
        "id": "F61V1ksPmZF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')\n",
        "X_train_tfidf = tfidf.fit_transform(df_train_clean[\"full_text\"])\n",
        "X_test_tfidf = tfidf.transform(df_test[\"full_text\"])"
      ],
      "metadata": {
        "id": "FMbDGm7Vmbeo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SentenceTransformer Embeddings"
      ],
      "metadata": {
        "id": "kB-qrFqamfz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_st = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "X_train_emb = model_st.encode(df_train_clean[\"full_text\"].tolist(), convert_to_tensor=False) # Convert to list\n",
        "X_test_emb = model_st.encode(df_test[\"full_text\"].tolist(), convert_to_tensor=False) # Convert to list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h6TCUOimfV1",
        "outputId": "836204a4-3849-4f70-c6d0-649ba014f613"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelling"
      ],
      "metadata": {
        "id": "9SQHRWL9nTt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_params = {\n",
        "    \"n_estimators\": 1000,\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"num_leaves\": 31,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"random_state\": 42\n",
        "}\n",
        "model = MultiOutputRegressor(LGBMRegressor(**lgbm_params))"
      ],
      "metadata": {
        "id": "GxeqxQ3dnTI-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df_train_clean[score_cols].values\n",
        "print(X_train_tfidf.shape[0], train_extra_features.shape[0], X_train_emb.shape[0], y_train.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB6zsTXz4ZBz",
        "outputId": "af39f0a7-20b5-47af-8474-a1cca2d8175e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9909 9909 9909 9909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix, hstack\n",
        "\n",
        "# Gabungkan semua fitur\n",
        "X_train_final = hstack([\n",
        "    X_train_tfidf,\n",
        "    csr_matrix(train_extra_features),\n",
        "    csr_matrix(X_train_emb)\n",
        "])\n",
        "\n",
        "X_test_final = hstack([\n",
        "    X_test_tfidf,\n",
        "    csr_matrix(test_extra_features),\n",
        "    csr_matrix(X_test_emb)\n",
        "])\n",
        "\n",
        "# Target\n",
        "y_train = df_train_clean[score_cols].values"
      ],
      "metadata": {
        "id": "GM7nJjjW5Eky"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "\n",
        "# Custom MSE untuk multioutput\n",
        "def mse_multioutput(y_true, y_pred):\n",
        "    return -mean_squared_error(y_true, y_pred)  # tanda minus supaya makin kecil makin baik\n",
        "\n",
        "mse_scorer = make_scorer(mse_multioutput)\n",
        "\n",
        "try:\n",
        "    print(\"X_train_final:\", X_train_final.shape)\n",
        "    print(\"y_train:\", y_train.shape)\n",
        "except NameError as e:\n",
        "    print(\"Variabel belum ada:\", e)\n",
        "\n",
        "# Cross Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(model, X_train_final, y_train, cv=kf, scoring=mse_scorer)\n",
        "print(\"CV MSE:\", -cv_scores.mean())\n",
        "\n",
        "# Train Final Model\n",
        "model.fit(X_train_final, y_train)\n",
        "y_pred_train = model.predict(X_train_final)\n",
        "mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "print(f\"Train MSE: {mse_train:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TzR_w1lnf-t",
        "outputId": "224a1a90-41d9-49b4-b457-74bbcca35d10"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_final: (9909, 5393)\n",
            "y_train: (9909, 4)\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.470411 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362486\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5388\n",
            "[LightGBM] [Info] Start training from score 6.650435\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.685643 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362486\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5388\n",
            "[LightGBM] [Info] Start training from score 6.701590\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.093041 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362486\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5388\n",
            "[LightGBM] [Info] Start training from score 6.234767\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.647731 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362486\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5388\n",
            "[LightGBM] [Info] Start training from score 6.172890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.609829 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362205\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5389\n",
            "[LightGBM] [Info] Start training from score 6.650309\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.600457 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362205\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5389\n",
            "[LightGBM] [Info] Start training from score 6.707456\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.601841 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362205\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5389\n",
            "[LightGBM] [Info] Start training from score 6.229090\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.812523 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362205\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5389\n",
            "[LightGBM] [Info] Start training from score 6.172575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.607679 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362224\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5390\n",
            "[LightGBM] [Info] Start training from score 6.658950\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.097991 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362224\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5390\n",
            "[LightGBM] [Info] Start training from score 6.713006\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.647589 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362224\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5390\n",
            "[LightGBM] [Info] Start training from score 6.237038\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.639618 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362224\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5390\n",
            "[LightGBM] [Info] Start training from score 6.173142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.581213 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362061\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5389\n",
            "[LightGBM] [Info] Start training from score 6.659581\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.728825 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362061\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5389\n",
            "[LightGBM] [Info] Start training from score 6.717926\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.768299 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362061\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5389\n",
            "[LightGBM] [Info] Start training from score 6.242778\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.638965 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362061\n",
            "[LightGBM] [Info] Number of data points in the train set: 7927, number of used features: 5389\n",
            "[LightGBM] [Info] Start training from score 6.179828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.633953 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362334\n",
            "[LightGBM] [Info] Number of data points in the train set: 7928, number of used features: 5390\n",
            "[LightGBM] [Info] Start training from score 6.658552\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.766063 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362334\n",
            "[LightGBM] [Info] Number of data points in the train set: 7928, number of used features: 5390\n",
            "[LightGBM] [Info] Start training from score 6.711087\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.645133 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362334\n",
            "[LightGBM] [Info] Number of data points in the train set: 7928, number of used features: 5390\n",
            "[LightGBM] [Info] Start training from score 6.235558\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.689574 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 362334\n",
            "[LightGBM] [Info] Number of data points in the train set: 7928, number of used features: 5390\n",
            "[LightGBM] [Info] Start training from score 6.173751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV MSE: 1.1947969784286276\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.834344 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 410079\n",
            "[LightGBM] [Info] Number of data points in the train set: 9909, number of used features: 5393\n",
            "[LightGBM] [Info] Start training from score 6.655566\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.787620 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 410079\n",
            "[LightGBM] [Info] Number of data points in the train set: 9909, number of used features: 5393\n",
            "[LightGBM] [Info] Start training from score 6.710213\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.802246 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 410079\n",
            "[LightGBM] [Info] Number of data points in the train set: 9909, number of used features: 5393\n",
            "[LightGBM] [Info] Start training from score 6.235846\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.791327 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 410079\n",
            "[LightGBM] [Info] Number of data points in the train set: 9909, number of used features: 5393\n",
            "[LightGBM] [Info] Start training from score 6.174437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train MSE: 0.1297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = model.predict(X_test_final)\n",
        "submission = pd.DataFrame(y_test_pred, columns=score_cols)\n",
        "submission.index = submission.index + 1\n",
        "submission.reset_index(inplace=True)\n",
        "submission.rename(columns={\"index\": \"ID\"}, inplace=True)\n",
        "submission.to_csv(\"submission_lgbm_advanced.csv\", index=False)\n",
        "print(\"Saved: submission_lgbm_advanced.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeNUzSF5nsyc",
        "outputId": "f84f7a87-542d-4b7b-c62f-aeed6a60d454"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: submission_lgbm_advanced.csv\n"
          ]
        }
      ]
    }
  ]
}